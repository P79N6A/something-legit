TODO
-tracking node set selection algorithm
-query from aylien start-stop times of these peripheral entities
-Construct KG per time interval
-Link price per asset node
-Train/Validate/Test on the spatial KG
-Do the same for full dataset

Aylien
	-Alexa 1...10000
		Entity in title: 28756 per week (+2500 from seed set). projected for 5 years: 8,126,560.
		Underestimated: these are only entities (350 entities) discovered in 1 week.
		Overestimated: these articles queried from beginning to end, when it should be first mentioned to deactivation
	-Potentially helpful features: sentiment, source rank

Cleaning/Proprocessing
Remove content after " - " or " | " in title, as it's frequently the publishers name
If ever need to majorly cut down on articles: Don't include countries

Anti-type:
	-Film
	-TelevisionShow
	-Fictional Character
	-Check whether or not dbpedia name is a named entity
		-'http://dbpedia.org/resource/Chief_technology_officer',
	False negatives:
		'http://dbpedia.org/resource/Surface_Pro',
		'http://dbpedia.org/resource/WhatsApp',
		'http://dbpedia.org/resource/Ipad_Pro',
		'http://dbpedia.org/resource/Macbook',
		'http://dbpedia.org/resource/OnePlus',
		'http://dbpedia.org/resource/3M',
		'http://dbpedia.org/resource/Instagram',
		'http://dbpedia.org/resource/Ripple_(payment_protocol)',
		'http://dbpedia.org/resource/Spotify',
		'http://dbpedia.org/resource/Xbox',
		'http://dbpedia.org/resource/Android_(operating_system)',
	But 80/100 good filters


for seed entity e
	for e article title
		if (no other entities)
			vectorize and submit to e set
		else 
			if (other entity is novel)
				initialize and track node
	 		vectorize relation and submit to e<->e' set (classify who is object and who is subject, handle >2 entities in title)

	for e article body
		Find sentences containing e, vectorize and submit to e set

for peripheral entity e
	for e article title
		if (no other entities)
			vectorize and submit to e set
		else 
			if (other entity is novel)
				continue
			else
	 			vectorize relation and submit to e<->e' set (classify who is object and who is subject, handle >2 entities in title)

	for e article body
		Find sentences containing e, vectorize and submit to e set


CONSTRUCT GRAPH ALGORITHM FOR INPUT DATA CREATION

graph:
	-interval_id, {node}, {edge}
		-Node: (url, last_seed_edge_update_time, mentions = [mentions], <encoded state for learning>, price, type?)
			-Mention: (sentence, article_id?, vectorize method)
		-Edge: (source_url, sink_url, mentions = [mentions], <encoded state for learning>, type?)

article:
	(title, body, NEL annotations, sentiment?, source rank?)

Params: interval length I, inactivity_threshold C, START_DATE, END_DATE
Initialize graph_state: (N = {seed nodes}, E = {})

Live version
	-getArticles is an api request
	-ConstructGraph is called every I minutes with timeframe (Now - I, Now)
Historical version
	-getArticles is a historical query of a certain block of articles and a request for non-seed tracked entities
	-NextGraph is called iteratively (Ii, I(i+1)) for i in range((END_DATE - STARTDATE) / I)

NextGraph(prev_graph g):
	articles = getArticles(g.tracked_nodes, timeframe)

	(a title must have at least 1 tracked entity, and >= 0 trackable entities)
	for a in article:
		preprocess(a)
		entity_link(a)
		parse_dependency_graph(a)
		connect(a, g)

	return g

connect(article_graph, entity_graph):